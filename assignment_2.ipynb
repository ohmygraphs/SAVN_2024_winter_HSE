{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0cc407",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "### This notebook consists of 2 parts: \n",
    "    - Page rank, HITS;\n",
    "    - Community detection\n",
    "\n",
    "### You can receive max 10 points for both.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c1f2e5",
   "metadata": {},
   "source": [
    "## Complete [this form](https://forms.gle/jvgXHSMaNvygWvCz5) with your name, email and .ipynb until 12.03 23:59 msk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b72b65",
   "metadata": {},
   "source": [
    "# Page rank and HITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af0d1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637cbaaf",
   "metadata": {},
   "source": [
    "### Task 1. PageRank algorithm (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab45779",
   "metadata": {},
   "source": [
    "Implement PageRank algorithm. A function `page_rank` takes a graph, transition coefficient `alpha` and number of iterations `k`. The function returns np.array of PageRank scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afd2b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank(nodes : np.ndarray, edges : List[np.ndarray], alpha : float, k : int) -> np.ndarray:\n",
    "    P = transition_matrix(edges)\n",
    "    v = teleportation_vector(edges)\n",
    "    rank = np.ones(nodes.shape[0]) / nodes.shape[0]\n",
    "    for _ in range(k):\n",
    "        rank = update_rank(rank, P, v, alpha)\n",
    "    return rank / rank.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16243964",
   "metadata": {},
   "source": [
    "Write a function `transition_matrix` that takes a np.array with an adjacency list and returns a np.array with a transition matrix where an entry $p_{ij}$ equals to probability of going to $j$ if we are in $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff1d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(edges : List[np.ndarray]) -> np.ndarray:\n",
    "    # Your code here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7193e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[0, 1, 1], # probability P(0→1) = P(0→2) = 1/2\n",
    "     [0, 0, 1], # probability P(1→2) = 1\n",
    "     [1, 0, 0]] # probability P(2→0) = 1\n",
    "A = np.array(A)\n",
    "tran_sum = transition_matrix(A).sum(axis=1)\n",
    "assert tran_sum[0] == tran_sum[1] == tran_sum[2] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b807e",
   "metadata": {},
   "source": [
    "Write a function `teleportation_vector` that takes a np.array with an adjacency list and returns a np.array with a teleportation vector where $p_i$ is a probability to teleport to a node $i$ (by default it is a uniform distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f198c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teleportation_vector(nodes : np.ndarray) -> np.ndarray:\n",
    "    # Your code here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert teleportation_vector(A).sum() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c307fad",
   "metadata": {},
   "source": [
    "Write a function `update_rank`. Check the function `page_rank` to understand parameters. An iterative process is defined as\n",
    "\n",
    "$$\\begin{matrix}\n",
    "r &=& \\text{transition} &+& \\text{teleportation}\\\\\n",
    "r &=& \\alpha P^T r &+& (1 - \\alpha)v\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "where $P$ is a transition matrix, $v$ is a teleportation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd01665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rank(rank : np.ndarray, P : np.ndarray, v : np.ndarray, alpha : float) -> np.ndarray:\n",
    "    # Your code here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c5a6df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_list(edges : np.array) -> List[np.ndarray]:\n",
    "    # Your code here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.path_graph(6, create_using=nx.DiGraph)\n",
    "nodes = np.array(G.nodes)\n",
    "edges = np.array(G.edges)\n",
    "adj_list = get_adj_list(edges)\n",
    "pr = page_rank(nodes, adj_list, 0.9, 100)\n",
    "assert np.all(pr[1:] - pr[:-1] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e4386",
   "metadata": {},
   "source": [
    "### Task 2. HITS (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aefb62",
   "metadata": {},
   "source": [
    "In this task we will try to find authorities and hubs in political blogs and visualize them. The data is provided from [Political blogosphere Feb. 2005](http://vlado.fmf.uni-lj.si/pub/networks/data/mix/mixed.htm) dataset.\n",
    "\n",
    "The graph contains parallel edges, but HITS algorithm only works without parallel edges. The simplest way to drop parallel edges is to convert a directed multigraph into a directed graph.\n",
    "\n",
    "Write a function `hits_polblogs` that takes a path to a gml file with data and returns a tuple with a graph and two dictionaries of the form\n",
    "* `{node: value}`\n",
    "\n",
    "The first dictionary is hub scores, the second one is authority scores. That is, a full output is `(nodes, adj_list, hub, auth)`. Apply `nx.hits` to calculate hub and authority scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d7a8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_polblogs(filename : str) -> [np.array, List[np.ndarray], dict, dict]:\n",
    "    # Your code here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/polblogs.gml'\n",
    "open('polblogs.gml', 'wb').write(requests.get(url).content)\n",
    "_, _, hub, auth = hits_polblogs('polblogs.gml')\n",
    "assert len(hub.values()) == len(auth.values()) == 1490\n",
    "assert round(max(hub.values()), 4) == 0.0069\n",
    "assert round(max(auth.values()), 4) == 0.015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec7036",
   "metadata": {},
   "source": [
    "There are many edges and nodes and it makes hard to draw the whole graph. Then, let us draw a scatter plot with hub and authority scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(hub.values(), auth.values(), s=7)\n",
    "plt.xlabel('Hub')\n",
    "plt.ylabel('Authority')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bc92c",
   "metadata": {},
   "source": [
    "Next, draw a graph with 14 nodes: top 7 authorities and top 7 hubs. Hubs will be on the left, authorities will be on the right.\n",
    "\n",
    "Write a function `hits_visualization` that takes a graph, hub, authority dictionaries, the number of top nodes and returns a dictionary with keys:\n",
    "* `h_top` — np.array of top nodes by hub score\n",
    "* `a_top` — np.array of top nodes by authority score\n",
    "* `subG` — subgraph of `G` with top nodes only\n",
    "* `h_vals` — np.array with hub scores (in initial graph) of top nodes that ordered by `subG.nodes` view \n",
    "* `a_vals` — the same for authority score\n",
    "* `pos` — dictionary with keys are nodes and values are x-y positions of the form\n",
    "\n",
    "`{node: [x, y]}` where \n",
    "* x equals to 0 if it is a hub and 1 if it is a authority\n",
    "* y equals to an index of top array\n",
    "\n",
    "That is, x could be 0 or 1 and y could be 0, 1, ..., 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7230b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_visualization(nodes : np.ndarray, edges : List[np.ndarray], hub : dict, auth : dict, top : np.ndarray) -> dict:\n",
    "    # Your code here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc504c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.array(G.nodes)\n",
    "edges = np.array(G.edges)\n",
    "adj_list = get_adj_list(edges)\n",
    "vi = hits_visualization(nodes, adj_list, hub, auth, 7)\n",
    "h_top, a_top = vi['h_top'], vi['a_top']\n",
    "h_vals, a_vals = vi['h_vals'], vi['a_vals']\n",
    "subG, pos = vi['subG'], vi['pos']\n",
    "assert h_top.shape[0] == a_top.shape[0] == int(len(subG) / 2) == 7\n",
    "assert 'politicalstrategy.org' == h_top[0]\n",
    "assert 'talkingpointsmemo.com' in a_top\n",
    "assert h_vals.shape == a_vals.shape == (14,)\n",
    "assert h_vals.max() < 0.0069\n",
    "assert 0 <= a_vals.min()\n",
    "assert pos['atrios.blogspot.com'] == [1, 2]\n",
    "assert pos['juancole.com'] == [1, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df5157",
   "metadata": {},
   "source": [
    "Networkx allows to draw nodes, edges, labels separately. In this case, we need to fix a layout and then draw a graph by layers. Let us draw a graph via `nx.draw_networkx`, then draw right labels and then draw left labels via `nx.draw_networkx_labels`. Also we will crop labels with more than 15 symbols to fit on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8*2))\n",
    "\n",
    "h_labels = {i:i[:15] if len(i)<=15 else i[:15] + '...' for i in h_top}\n",
    "a_labels = {i:i[:15] if len(i)<=15 else i[:15] + '...' for i in a_top}\n",
    "a_pos = {node:(pos[node][0] + 0.1, pos[node][1]) for node in pos}\n",
    "h_pos = {node:(pos[node][0] - 0.1, pos[node][1]) for node in pos}\n",
    "\n",
    "cases = [[1, 'tab:purple', a_vals, 'Node size by authority score'], \n",
    "         [2, 'tab:cyan', h_vals, 'Node size by hub score']]\n",
    "for i, color, vals, t in cases:\n",
    "    plt.subplot(2, 1, i)\n",
    "    plt.gca().axis('off')\n",
    "    nx.draw_networkx(\n",
    "        subG,\n",
    "        pos,\n",
    "        width=0.5,\n",
    "        with_labels=False,\n",
    "        edgecolors='black',\n",
    "        node_size=vals*1e5,\n",
    "        node_color=color\n",
    "    )\n",
    "    nx.draw_networkx_labels(\n",
    "        subG,\n",
    "        pos=a_pos,\n",
    "        labels=a_labels,\n",
    "        horizontalalignment='left'\n",
    "    )\n",
    "    nx.draw_networkx_labels(\n",
    "        subG,\n",
    "        pos=h_pos,\n",
    "        labels=h_labels,\n",
    "        horizontalalignment='right'\n",
    "    )\n",
    "\n",
    "    plt.xlim(-0.5, 1.5)\n",
    "    plt.title(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39206e83",
   "metadata": {},
   "source": [
    "## Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b22cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from zlib import adler32\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6845d4a4",
   "metadata": {},
   "source": [
    "Try to detect communities in Les Miserables graph by Agglomerative clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from(nx.les_miserables_graph().edges)\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw_networkx_nodes(G, pos, node_color='white', edgecolors='black', node_size=100)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fcf9c",
   "metadata": {},
   "source": [
    "### Agglomerative clustering (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e0646",
   "metadata": {},
   "source": [
    "Agglomerative clustering is an iterative procedure that unions similar clusters using a similarity matrix, but since we will run `sklearn.cluster.AgglomerativeClustering`, we need to pass a _distance_ matrix. So, first we need to choose a similarity measure and then convert it into a distance. Let us do it via SimRank measure that is defined as follows: _two objects are considered to be similar if they are referenced by similar objects_. Since SimRank takes values on the interval [0, 1], let us define a distance as\n",
    "\n",
    "$$\\text{Distance}= 1 - \\text{SimRank}$$\n",
    "\n",
    "Write a function `simrank_distance` that takes a graph and returns a distance matrix based on SimRank. Use `nx.simrank_similarity_numpy`. The distance matrix should be _absolutely_ symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b796a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simrank_distance(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6dcad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = simrank_distance(G)\n",
    "assert distance.shape == (77, 77)\n",
    "assert np.diagonal(distance).sum() == 0\n",
    "assert np.allclose(distance, distance.T, rtol=0, atol=0)\n",
    "assert distance[52, 68] <= distance[1, 19]\n",
    "assert distance[45, 29] <= distance[38, 46]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330bb5d",
   "metadata": {},
   "source": [
    "Then let us cluster nodes using `scipy.cluster.hierarchy.linkage`. The method takes distancies and returns an np.array with a matrix `Z` where every i-th row consists of\n",
    "* `Z[i, 0]` and `Z[i, 1]` are indexes of combined clusters\n",
    "* `Z[i, 2]` is the distance between combined clusters\n",
    "* `Z[i, 3]` is the number of observations in combined clusters\n",
    "\n",
    "Cluster with an index `n+i` is described in a i-th row of the matrix `Z`. Clusters with indexes less than `n+1` are initial nodes. The method `scipy.cluster.hierarchy.dendrogram` uses the matrix `Z` to plot a dendrogram. Let us look at a dendrogram of Les Miserables graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d216370",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "linked = linkage(squareform(distance), 'complete')\n",
    "dendrogram(linked, labels=list(G.nodes), \n",
    "           leaf_font_size=12)\n",
    "plt.plot([0, 800], [0.89, 0.89], 'k--', c='tab:red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f670d2",
   "metadata": {},
   "source": [
    "Then we need to select a horizontal line that gives us a partitioning of the graph. There are two approaches: select the number of clusters, and select the maximal distance between clusters. For example, if we select a horicontal line with maximal distance 0.89 (a red line on the plot) then the number of clusters will be 4.\n",
    "\n",
    "Write a function `agglomerative_clustering` that takes a distance matrix, maximal distance between clusters and returns an np.array with labels of clusters. Use `sklearn.cluster.AgglomerativeClustering` with complete linkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2efe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerative_clustering(distance, max_distance):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4020eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(agglomerative_clustering(distance, 0.8))) == 17\n",
    "assert len(set(agglomerative_clustering(distance, 0.89))) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815ef80",
   "metadata": {},
   "source": [
    "The graph with maximal distance 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = agglomerative_clustering(distance, 0.87)\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw_networkx_nodes(\n",
    "    G, \n",
    "    pos,\n",
    "    cmap=plt.cm.rainbow,\n",
    "    node_color=labels, \n",
    "    node_size=100, \n",
    "    linewidths=1, \n",
    "    edgecolors='black'\n",
    ")\n",
    "nx.draw_networkx_edges(\n",
    "    G,\n",
    "    pos,\n",
    "    alpha=0.2,\n",
    "    edge_color='black'\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ecd36",
   "metadata": {},
   "source": [
    "### Task 7. Louvain method (2.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1625ac",
   "metadata": {},
   "source": [
    "Louvain method is one of the most cited works in the community detection literature. It is a simple method to extract the community structure of large networks. This method is a heuristic method that is based on modularity optimization. Let us consider this method on a fractal graph that can represent some biological structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractal_graph(n, k, G):\n",
    "    if k == 0:\n",
    "        return G\n",
    "    for node in list(G.nodes):\n",
    "        newG = nx.complete_graph(n)\n",
    "        newG = nx.relabel_nodes(newG, {node:max(G.nodes)+node+1 for node in newG.nodes})\n",
    "        G = nx.union(G, newG)\n",
    "        for edge in G.edges(node):\n",
    "            G.add_edge(list(G.nodes)[-1], edge[1])\n",
    "        G.remove_node(node)\n",
    "    return fractal_graph(n, k-1, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7074053",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fractalG = fractal_graph(n, 3, nx.complete_graph(n))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "frac_pos = nx.kamada_kawai_layout(fractalG)\n",
    "nx.draw_networkx_nodes(fractalG, frac_pos, node_color='white', \n",
    "                       edgecolors='black', node_size=100)\n",
    "nx.draw_networkx_edges(fractalG, frac_pos, alpha=0.3)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b1801",
   "metadata": {},
   "source": [
    "Louvain method is a greedy algorithm of modularity gain that is described as: \n",
    "\n",
    "Phase 1\n",
    "1. Put each node in its own community\n",
    "2. For every node, calculate modularity gain by removing it from its community and placing it in neighbor's community\n",
    "3. Put a node in the community with maximal modularity gain\n",
    "4. Repeat 2, 3 until modularity stops increasing\n",
    "\n",
    "Phase 2\n",
    "1. Merge communities into ”super nodes”\n",
    "2. Convert edges inside community into self loop, edges between communities into parallel edges\n",
    "\n",
    "Repeat phases 1, 2 until modularity stops increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def louvain_method(G):\n",
    "    \n",
    "    # Phase 1\n",
    "    communities = unfolded_communities(G)\n",
    "    labels = []\n",
    "    for node in G.nodes:\n",
    "        for i, c in enumerate(communities):\n",
    "            if node in c:\n",
    "                labels.append(i)\n",
    "    \n",
    "    # Phase 2\n",
    "    nextG = nx.empty_graph(len(communities), nx.MultiGraph)\n",
    "    for e in G.edges:\n",
    "        for i in range(len(communities)):\n",
    "            for j in range(len(communities)):\n",
    "                if e[0] in communities[i] and e[1] in communities[j]:\n",
    "                    nextG.add_edge(i, j)\n",
    "                    \n",
    "    # Shuffle colors for better visualization\n",
    "    palette = np.unique(labels)\n",
    "    key = np.random.permutation(palette)\n",
    "    labels = key[np.digitize(labels, palette, right=True)]\n",
    "    \n",
    "    return communities, labels, nextG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfea0a5",
   "metadata": {},
   "source": [
    "Write a function `unfolded_communities` that takes a graph, performs Phase 1 and returns np.array of communities with nodes. For example, if there are two communitites: the first is [1,2] and the second is [3,4,5] then the output will be [[1,2],[3,4,5]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ec62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfolded_communities(G):\n",
    "    # Proposed template:\n",
    "    communities = [[n] for n in G.nodes] # initial partition\n",
    "    prev_max_modularity = -np.inf\n",
    "    max_modularity = nx.algorithms.community.modularity(G, communities)\n",
    "    while max_modularity > prev_max_modularity:\n",
    "        prev_max_modularity = max_modularity\n",
    "        for node in np.random.permutation(G.nodes):\n",
    "            '''\n",
    "            1) Remove the node from the initial community.\n",
    "            2) Iterate all neighboring communities and move the node\n",
    "               into a community with the maximum modularity gain. If \n",
    "               there is no modularity gain, return the node into the \n",
    "               initial community.\n",
    "            '''\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "    return [c for c in communities if len(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0cc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fractalG = fractal_graph(n, 2, nx.complete_graph(n))\n",
    "iterG = fractalG.copy()\n",
    "communities, labels, nextG = louvain_method(iterG)\n",
    "\n",
    "assert len(set(labels)) == 16\n",
    "assert len(set(labels[52:56])) == 1\n",
    "assert len(set(labels[52:57])) == 2\n",
    "assert nextG.number_of_nodes() == 16\n",
    "assert round(np.linalg.det(nx.to_numpy_array(nextG)) * 1e-10, 4) == 136.5257"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b81de9",
   "metadata": {},
   "source": [
    "Let us see unfolding iterations. For every iteration we draw a graph where node color corresponds to the unfolded community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fractalG = fractal_graph(n, 3, nx.complete_graph(n))\n",
    "iterG = fractalG\n",
    "\n",
    "plt.figure(figsize=(7, 7*3))\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    communities, labels, nextG = louvain_method(iterG)\n",
    "    iter_pos = nx.kamada_kawai_layout(iterG)\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        iterG,\n",
    "        iter_pos,\n",
    "        cmap=plt.cm.rainbow,\n",
    "        node_color=labels,\n",
    "        edgecolors='black',\n",
    "        node_size=100)\n",
    "    nx.draw_networkx_edges(\n",
    "        iterG,\n",
    "        iter_pos,\n",
    "        node_size=100)\n",
    "    plt.axis('off')\n",
    "    plt.title(\n",
    "        '{} nodes, {} communities \\nModularity {:.2f}'.format(\n",
    "            len(iterG), len(communities), nx.community.modularity(iterG, communities)))\n",
    "    iterG = nextG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
